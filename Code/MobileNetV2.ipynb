{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建转换器\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((90, 90)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "test_transfrom = transforms.Compose([\n",
    "    transforms.Resize((90, 90)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49601\n",
      "{'Angry': 3422, 'Disgust': 3285, 'Fear': 1602, 'Happy': 24034, 'Neutral': 10908, 'Sad': 2875, 'Surprise': 3475}\n"
     ]
    }
   ],
   "source": [
    "#计算每个类别的图片数量\n",
    "train_path = 'D:\\Csci323\\Emotion-domestic\\Emotion-domestic\\Train'\n",
    "train_dataset = ImageFolder(root=train_path, transform=train_transform)\n",
    "classes_name = train_dataset.classes\n",
    "class_count = {}\n",
    "for i in classes_name:\n",
    "    class_path = os.path.join(train_path,i)\n",
    "    image_count = len(os.listdir(class_path))\n",
    "    class_count[i] = image_count\n",
    "print(len(train_dataset))\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个类别的权重\n",
    "class_sample_counts = [3422, 3285, 1602, 24034, 10908, 2875, 3475]\n",
    "weights = 1. / np.array(class_sample_counts)\n",
    "samples_weights = np.array([weights[label] for _, label in train_dataset.samples])\n",
    "\n",
    "\n",
    "# 创建采样器\n",
    "sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights) * 2, replacement=True)\n",
    "\n",
    "# 使用采样器创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder(root='D:\\Csci323\\Emotion-domestic\\Emotion-domestic\\Test', transform=test_transfrom)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\0\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Users\\0\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\0/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-b0353104.pth\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 58.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的mobilenet模型\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# 修改最后的全连接层以适应数据集的7个类别\n",
    "num_ftrs = model.classifier[-1].in_features\n",
    "model.classifier[-1] = nn.Linear(num_ftrs, 7)\n",
    "\n",
    "#将模型加载到GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.646\n",
      "Accuracy of the network on the test images: 15.78%\n",
      "Epoch 2 loss: 0.366\n",
      "Accuracy of the network on the test images: 17.14%\n",
      "Epoch 3 loss: 0.285\n",
      "Accuracy of the network on the test images: 19.26%\n",
      "Epoch 4 loss: 0.243\n",
      "Accuracy of the network on the test images: 23.10%\n",
      "Epoch 5 loss: 0.208\n",
      "Accuracy of the network on the test images: 24.62%\n",
      "Epoch 6 loss: 0.174\n",
      "Accuracy of the network on the test images: 25.50%\n",
      "Epoch 7 loss: 0.156\n",
      "Accuracy of the network on the test images: 26.50%\n",
      "Epoch 8 loss: 0.136\n",
      "Accuracy of the network on the test images: 26.98%\n",
      "Epoch 9 loss: 0.122\n",
      "Accuracy of the network on the test images: 25.24%\n",
      "Epoch 10 loss: 0.110\n",
      "Accuracy of the network on the test images: 29.20%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs,labels = inputs.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} loss: {running_loss / 3100:.3f}')\n",
    "# 测试模型\n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images,labels = images.to(device),labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the test images: {100 * correct / total:.2f}%')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'D:\\Csci323\\mobilenet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
