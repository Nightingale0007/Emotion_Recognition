{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((90, 90)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((90, 90)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算每个类别的图片数量\n",
    "train_path = 'D:\\Csci323\\Emotion-domestic\\Emotion-domestic\\Train'\n",
    "train_dataset = ImageFolder(root=train_path, transform=train_transform)\n",
    "# 计算每个类别的权重\n",
    "class_sample_counts = [3422, 3285, 1602, 24034, 10908, 2875, 3475]\n",
    "weights = 1. / np.array(class_sample_counts)\n",
    "samples_weights = np.array([weights[label] for _, label in train_dataset.samples])\n",
    "# 创建采样器\n",
    "sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights) * 2, replacement=True)\n",
    "# 使用采样器创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4)\n",
    "\n",
    "test_dataset = ImageFolder(root='D:\\Csci323\\Emotion-domestic\\Emotion-domestic\\Test', transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\0\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Users\\0\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的ResNet50模型\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# 修改最后的全连接层以适应FER-2013的7个类别\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 7)\n",
    "\n",
    "#将模型加载到GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.559\n",
      "Accuracy of the network on the test images: 20.50%\n",
      "Epoch 2 loss: 0.267\n",
      "Accuracy of the network on the test images: 22.98%\n",
      "Epoch 3 loss: 0.180\n",
      "Accuracy of the network on the test images: 27.30%\n",
      "Epoch 4 loss: 0.137\n",
      "Accuracy of the network on the test images: 29.42%\n",
      "Epoch 5 loss: 0.107\n",
      "Accuracy of the network on the test images: 28.60%\n",
      "Epoch 6 loss: 0.086\n",
      "Accuracy of the network on the test images: 31.78%\n",
      "Epoch 7 loss: 0.073\n",
      "Accuracy of the network on the test images: 30.50%\n",
      "Epoch 8 loss: 0.064\n",
      "Accuracy of the network on the test images: 32.88%\n",
      "Epoch 9 loss: 0.056\n",
      "Accuracy of the network on the test images: 35.18%\n",
      "Epoch 10 loss: 0.044\n",
      "Accuracy of the network on the test images: 33.40%\n",
      "Epoch 11 loss: 0.048\n",
      "Accuracy of the network on the test images: 34.26%\n",
      "Epoch 12 loss: 0.044\n",
      "Accuracy of the network on the test images: 37.34%\n",
      "Epoch 13 loss: 0.034\n",
      "Accuracy of the network on the test images: 37.42%\n",
      "Epoch 14 loss: 0.042\n",
      "Accuracy of the network on the test images: 37.94%\n",
      "Epoch 15 loss: 0.028\n",
      "Accuracy of the network on the test images: 39.00%\n",
      "Epoch 16 loss: 0.031\n",
      "Accuracy of the network on the test images: 38.76%\n",
      "Epoch 17 loss: 0.023\n",
      "Accuracy of the network on the test images: 39.88%\n",
      "Epoch 18 loss: 0.026\n",
      "Accuracy of the network on the test images: 38.62%\n",
      "Epoch 19 loss: 0.022\n",
      "Accuracy of the network on the test images: 39.64%\n",
      "Epoch 20 loss: 0.023\n",
      "Accuracy of the network on the test images: 39.04%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs,labels = inputs.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} loss: {running_loss / 3100:.3f}')\n",
    "    # 测试模型\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images,labels = images.to(device),labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the test images: {100 * correct / total:.2f}%')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'D:\\Csci323\\ResNET_50.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
